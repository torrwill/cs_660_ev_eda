{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis of Electric Vehicle Population Data\n",
    "\n",
    "- **Course:** CS660/71425 Mathematical Foundations of Analytics\n",
    "- **Instructor:** Prof. Sarbanes\n",
    "- **Group-1:** Will Torres, Mike Griffin, Watson Blair, Syed Abdul Mubashir, Mohammed Abdul Munaf\n",
    "- **Semester:** Fall 2024\n",
    "- **Project #:** 1\n",
    "- **Due Date:** 07-Oct-2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Description\n",
    "Exploratory Data Analysis (EDA) is essential for understanding, cleaning, and preparing data for further analysis in data science projects. This project focuses on analyzing the Electric Vehicle (EV) population dataset from Washington State, USA.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions to be Answered\n",
    "1. Which car manufacturers are most commonly used for EVs in Washington?\n",
    "2. What are the highest and lowest electric ranges in this dataset, and which car makers and models do they correspond to?\n",
    "3. Is the maximum electric range value unique? If not, which cars share this range?\n",
    "4. Is the minimum electric range value unique? If not, which cars share this range?\n",
    "5. How does the electric range vary between car makers and between models?\n",
    "6. Which are the top 5 cities adopting EVs?\n",
    "7. How does the EV adoption rate vary among car makers over the years?\n",
    "8. Is there a correlation between the electric range and the city of an EV?\n",
    "9. Which county has the greatest variety of EV car models?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Understand the Dataset Context\n",
    "- **Objective Clarification**\n",
    "- **Data Source Identification**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Import Libraries and Load Data\n",
    "- **Import Necessary Libraries:** `pandas`, `numpy`, `matplotlib`, `seaborn`\n",
    "- **Load the Dataset:** `EV_Population_WA_Data.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Imports\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\"\"\"Load Data\"\"\"\n",
    "rawData = pd.read_csv('./data/EV_Population_WA_Data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Initial Data Inspection\n",
    "- **View Data Structure:** `.head()`, `.info()`, `.describe()`\n",
    "- **Check Dimensions:** `.shape()`\n",
    "- **Identify Missing Values:** `.isnull().sum()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Data Cleaning\n",
    "- **Handle Missing/Incomplete Data**\n",
    "  - Range Data\n",
    "- **Handle Outliers**\n",
    "- **Correct Data Types**\n",
    "  - transform categorical data into numeric values for use in correlation operations \n",
    "  - \n",
    "- **Handle Duplicates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "normalizeUtility.<locals>.parseUtility() got an unexpected keyword argument 'axis'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 30\u001b[0m\n\u001b[1;32m     26\u001b[0m cleanData \u001b[38;5;241m=\u001b[39m convertEligibility(cleanData)\n\u001b[1;32m     28\u001b[0m cleanData \u001b[38;5;241m=\u001b[39m convertPostalCode(cleanData)\n\u001b[0;32m---> 30\u001b[0m cleanData \u001b[38;5;241m=\u001b[39m normalizeUtility(cleanData)\n",
      "Cell \u001b[0;32mIn[9], line 15\u001b[0m, in \u001b[0;36mnormalizeUtility\u001b[0;34m(argData)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;28mprint\u001b[39m(e)\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m row\n\u001b[0;32m---> 15\u001b[0m result \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mapply(parseUtility, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, result_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbroadcast\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\n\u001b[1;32m   4918\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4919\u001b[0m         func,\n\u001b[1;32m   4920\u001b[0m         convert_dtype\u001b[38;5;241m=\u001b[39mconvert_dtype,\n\u001b[1;32m   4921\u001b[0m         by_row\u001b[38;5;241m=\u001b[39mby_row,\n\u001b[1;32m   4922\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   4923\u001b[0m         kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m-> 4924\u001b[0m     )\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_map_values(\n\u001b[1;32m   1508\u001b[0m     mapper\u001b[38;5;241m=\u001b[39mcurried, na_action\u001b[38;5;241m=\u001b[39maction, convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype\n\u001b[1;32m   1509\u001b[0m )\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m algorithms\u001b[38;5;241m.\u001b[39mmap_array(arr, mapper, na_action\u001b[38;5;241m=\u001b[39mna_action, convert\u001b[38;5;241m=\u001b[39mconvert)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer(values, mapper, convert\u001b[38;5;241m=\u001b[39mconvert)\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/apply.py:1496\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard.<locals>.curried\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1495\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcurried\u001b[39m(x):\n\u001b[0;32m-> 1496\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n",
      "\u001b[0;31mTypeError\u001b[0m: normalizeUtility.<locals>.parseUtility() got an unexpected keyword argument 'axis'"
     ]
    }
   ],
   "source": [
    "from utils import calculateRange, calculateMSRP, convertEligibility, convertPostalCode\n",
    "# , normalizeUtility\n",
    "\n",
    "def normalizeUtility(argData: pd.DataFrame):\n",
    "    data = argData.copy(deep=True)\n",
    "\n",
    "    def parseUtility(row):\n",
    "        try:\n",
    "            row['Electric Utility'] = ','.join(row['Electric Utility'].replace('||', '|').split('|'))\n",
    "        except AttributeError as e:\n",
    "            print(row['Electric Utility'])\n",
    "            print(e)\n",
    "        return row\n",
    "    \n",
    "    result = data.apply(parseUtility, axis=1, result_type='broadcast')\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "cleanData = rawData.copy(deep=True)\n",
    "\n",
    "cleanData = calculateRange(cleanData)\n",
    "\n",
    "cleanData = calculateMSRP(cleanData) # Corrects aprox 10,000 records\n",
    "\n",
    "cleanData = convertEligibility(cleanData)\n",
    "\n",
    "cleanData = convertPostalCode(cleanData)\n",
    "\n",
    "cleanData = normalizeUtility(cleanData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cleanData[cleanData['Electric Utility'].dtype == float])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cleanData['Electric Utility'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Univariate Analysis\n",
    "- **Summary Statistics**\n",
    "- **Visualize Distributions:** histograms, box plots, bar charts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Bivariate Analysis\n",
    "- **Correlation Analysis**: (e.g., Pearson, Spearman)\n",
    "- **Cross-tabulation**\n",
    "- **Visualize Relationships:** scatter plots, box plots, heatmaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Multivariate Analysis\n",
    "- **Pairplot/Scatterplot Matrix**\n",
    "- **Multivariate Statistics**\n",
    "- **Advanced Visualizations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Feature Engineering\n",
    "- **Create New Features**\n",
    "- **Feature Transformation**\n",
    "- **Encoding Categorical Variables**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9: Handle Imbalanced Data (If Applicable)\n",
    "- **Resampling Techniques**: Use oversampling, under-sampling, or SMOTE if the target variable is imbalanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 10: Analyze and Validate Assumptions\n",
    "- **Check for Multicollinearity**: Use VIF (Variance Inflation Factor) to detect multicollinearity among predictors.\n",
    "- **Normality Testing**: Test if numerical data follows a normal distribution (e.g., using the Shapiro-Wilk test).\n",
    "- **Homoscedasticity**: Check the equality of variance across groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 11: Preliminary Insights and Hypotheses\n",
    "- **Identify Key Findings**\n",
    "- **Generate Hypotheses**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 12: Document and Communicate Findings\n",
    "- **Create Visual Summaries**\n",
    "- **Write a Summary Report**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 13: Next Steps\n",
    "- **Plan for Further Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 14: Review and Reiterate\n",
    "- **Review EDA**\n",
    "- **Iterate as Needed**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
