{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis of Electric Vehicle Population Data\n",
    "\n",
    "- **Course:** CS660/71425 Mathematical Foundations of Analytics\n",
    "- **Instructor:** Prof. Sarbanes\n",
    "- **Group-1:** Will Torres, Mike Griffin, Watson Blair, Syed Abdul Mubashir, Mohammed Abdul Munaf\n",
    "- **Semester:** Fall 2024\n",
    "- **Project #:** 1\n",
    "- **Due Date:** 07-Oct-2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Description\n",
    "Exploratory Data Analysis (EDA) is essential for understanding, cleaning, and preparing data for further analysis in data science projects. This project focuses on analyzing the Electric Vehicle (EV) population dataset from Washington State, USA.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions to be Answered\n",
    "1. Which car manufacturers are most commonly used for EVs in Washington?\n",
    "2. What are the highest and lowest electric ranges in this dataset, and which car makers and models do they correspond to?\n",
    "3. Is the maximum electric range value unique? If not, which cars share this range?\n",
    "4. Is the minimum electric range value unique? If not, which cars share this range?\n",
    "5. How does the electric range vary between car makers and between models?\n",
    "6. Which are the top 5 cities adopting EVs?\n",
    "7. How does the EV adoption rate vary among car makers over the years?\n",
    "8. Is there a correlation between the electric range and the city of an EV?\n",
    "9. Which county has the greatest variety of EV car models?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Understand the Dataset Context\n",
    "\n",
    "_Washington State Department of Licensing_'s dataset tracks **Battery Electric Vehicles** (BEVs) and **Plug-in Hybrid Electric Vehicles** (PHEVs) registered in Washington state. This dataset is updated monthly and offers insights into the electric vehicle population, categorized by county, postal code, and vehicle characteristics.\n",
    "\n",
    "**Key Dataset Details**:\n",
    "- Data Source: Washington State Department of Licensing.\n",
    "- Objective: To provide a comprehensive overview of electric vehicles registered in Washington, segmented by various geographical and vehicle-specific metrics. It helps track the adoption of electric vehicles across different regions.\n",
    "- Metadata: The dataset is updated regularly (most recently on September 16, 2024) and covers registered electric vehicles as of August 31, 2024.  \n",
    "\n",
    "**Notable Fields**:\n",
    "- VIN (1-10): The first 10 characters of the Vehicle Identification Number.\n",
    "- County/**City**/State/Postal Code: Geographic data identifying where the vehicle is registered.\n",
    "- **Model Year**, **Make**, **Model**: Vehicle characteristics.\n",
    "- Electric Vehicle Type: Whether the vehicle is a BEV or PHEV.\n",
    "- **Electric Range**: The distance a vehicle can travel on electric charge.\n",
    "- Legislative District: The political district in which the vehicle owner resides.  \n",
    "\n",
    "**Objective Clarification**:\n",
    "- The goal of using this data could be to analyze electric vehicle adoption trends in Washington, identify regions with the highest EV adoption, or track specific vehicle models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Import Libraries and Load Data\n",
    "- **Import Necessary Libraries:** `pandas`, `numpy`, `matplotlib`, `seaborn`\n",
    "- **Load the Dataset:** `EV_Population_WA_Data.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\"\"\"Load Data\"\"\"\n",
    "rawData = pd.read_csv('./data/EV_Population_WA_Data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Initial Data Inspection\n",
    "- **View Data Structure:** `.head()`, `.info()`, `.describe()`\n",
    "- **Check Dimensions:** `.shape()`\n",
    "- **Identify Missing Values:** `.isnull().sum()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Data Cleaning\n",
    "- **Handle Missing/Incomplete Data**\n",
    "  - Range Data\n",
    "- **Handle Outliers**\n",
    "- **Correct Data Types**\n",
    "  - transform categorical data into numeric values for use in correlation operations \n",
    "  - \n",
    "- **Handle Duplicates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "normalizeUtility.<locals>.parseUtility() got an unexpected keyword argument 'axis'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 30\u001b[0m\n\u001b[1;32m     26\u001b[0m cleanData \u001b[38;5;241m=\u001b[39m convertEligibility(cleanData)\n\u001b[1;32m     28\u001b[0m cleanData \u001b[38;5;241m=\u001b[39m convertPostalCode(cleanData)\n\u001b[0;32m---> 30\u001b[0m cleanData \u001b[38;5;241m=\u001b[39m normalizeUtility(cleanData)\n",
      "Cell \u001b[0;32mIn[9], line 15\u001b[0m, in \u001b[0;36mnormalizeUtility\u001b[0;34m(argData)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;28mprint\u001b[39m(e)\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m row\n\u001b[0;32m---> 15\u001b[0m result \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mapply(parseUtility, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, result_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbroadcast\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\n\u001b[1;32m   4918\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4919\u001b[0m         func,\n\u001b[1;32m   4920\u001b[0m         convert_dtype\u001b[38;5;241m=\u001b[39mconvert_dtype,\n\u001b[1;32m   4921\u001b[0m         by_row\u001b[38;5;241m=\u001b[39mby_row,\n\u001b[1;32m   4922\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   4923\u001b[0m         kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m-> 4924\u001b[0m     )\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_map_values(\n\u001b[1;32m   1508\u001b[0m     mapper\u001b[38;5;241m=\u001b[39mcurried, na_action\u001b[38;5;241m=\u001b[39maction, convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype\n\u001b[1;32m   1509\u001b[0m )\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m algorithms\u001b[38;5;241m.\u001b[39mmap_array(arr, mapper, na_action\u001b[38;5;241m=\u001b[39mna_action, convert\u001b[38;5;241m=\u001b[39mconvert)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer(values, mapper, convert\u001b[38;5;241m=\u001b[39mconvert)\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/apply.py:1496\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard.<locals>.curried\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1495\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcurried\u001b[39m(x):\n\u001b[0;32m-> 1496\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n",
      "\u001b[0;31mTypeError\u001b[0m: normalizeUtility.<locals>.parseUtility() got an unexpected keyword argument 'axis'"
     ]
    }
   ],
   "source": [
    "from utils import calculateRange, calculateMSRP, convertEligibility, purgeInternationalOutliers, convertPostalCode, imputeLocationData\n",
    "# Note: The questions pertain to the following columns:\n",
    "# Model Year, Model, Make, Electric Range, City, County\n",
    "# Focusing our data cleaning, prep, analysis, and feature engineering to these cols might be beneficial.\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "cleanData = rawData.copy(deep=True)\n",
    "\n",
    "cleanData = calculateRange(cleanData)\n",
    "\n",
    "cleanData = calculateMSRP(cleanData) # Corrects approx 10,000 records\n",
    "\n",
    "cleanData = convertEligibility(cleanData)\n",
    "\n",
    "cleanData = convertPostalCode(cleanData)\n",
    "\n",
    "cleanData = normalizeUtility(cleanData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cleanData[cleanData['Electric Utility'].dtype == float])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cleanData['Electric Utility'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Univariate Analysis\n",
    "- **Summary Statistics**\n",
    "- **Visualize Distributions:** histograms, box plots, bar charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary Statistics for categorical columns\n",
    "categorical_summary = df.describe(include=['object'])\n",
    "categorical_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing distributions for numerical variables\n",
    "num_cols = ['Electric Range', 'Base MSRP', 'Model Year']\n",
    "\n",
    "for col in num_cols:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.histplot(df[col], kde=True, bins=20)\n",
    "    plt.title(f'Histogram for {col}')\n",
    "    plt.show()\n",
    "\n",
    "# Box plots for numerical variables\n",
    "for col in num_cols:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.boxplot(x=df[col])\n",
    "    plt.title(f'Box Plot for {col}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 5 Cities with Most Electric Vehicles\n",
    "def plot_top_5_cities(df):\n",
    "    top_5_cities = df['City'].value_counts().nlargest(5)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=top_5_cities.values, y=top_5_cities.index, palette=\"viridis\")\n",
    "    plt.title('Top 5 Cities with Most Electric Vehicles')\n",
    "    plt.xlabel('Number of Electric Vehicles')\n",
    "    plt.ylabel('City')\n",
    "    plt.show()\n",
    "\n",
    "# Electric Vehicle Types Distribution by State (for Washington 'WA')\n",
    "def plot_ev_type_by_state(df, state='WA'):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.countplot(data=df[df.State == state], x='State', hue='Electric Vehicle Type', palette=\"viridis\")\n",
    "    plt.title(f'Electric Vehicle Types Distribution in {state}')\n",
    "    plt.xlabel('State')\n",
    "    plt.ylabel('Count of Electric Vehicles')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.legend(title='Electric Vehicle Type')\n",
    "    plt.show()\n",
    "\n",
    "# Top 10 and Bottom 10 Makes and Models Subplots\n",
    "def plot_top_bottom_makes_models(df):\n",
    "    # Data preparation for top and bottom makes and models\n",
    "    top_10_makes = df['Make'].value_counts().nlargest(10)\n",
    "    bottom_10_makes = df['Make'].value_counts().nsmallest(10)\n",
    "    top_10_models = df['Model'].value_counts().nlargest(10)\n",
    "    bottom_10_models = df['Model'].value_counts().nsmallest(10)\n",
    "\n",
    "    # Create subplots: 2 rows and 2 columns\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "\n",
    "    # Top 10 Makes\n",
    "    sns.barplot(x=top_10_makes.values, y=top_10_makes.index, ax=axes[0, 0], palette=\"viridis\")\n",
    "    axes[0, 0].set_title('Top 10 Makes of Electric Vehicles')\n",
    "    axes[0, 0].set_xlabel('Number of Electric Vehicles')\n",
    "    axes[0, 0].set_ylabel('Make')\n",
    "\n",
    "    # Bottom 10 Makes\n",
    "    sns.barplot(x=bottom_10_makes.values, y=bottom_10_makes.index, ax=axes[0, 1], palette=\"viridis\")\n",
    "    axes[0, 1].set_title('Bottom 10 Makes of Electric Vehicles')\n",
    "    axes[0, 1].set_xlabel('Number of Electric Vehicles')\n",
    "    axes[0, 1].set_ylabel('Make')\n",
    "\n",
    "    # Top 10 Models\n",
    "    sns.barplot(x=top_10_models.values, y=top_10_models.index, ax=axes[1, 0], palette=\"viridis\")\n",
    "    axes[1, 0].set_title('Top 10 Electric Vehicle Models')\n",
    "    axes[1, 0].set_xlabel('Number of Electric Vehicles')\n",
    "    axes[1, 0].set_ylabel('Model')\n",
    "\n",
    "    # Bottom 10 Models\n",
    "    sns.barplot(x=bottom_10_models.values, y=bottom_10_models.index, ax=axes[1, 1], palette=\"viridis\")\n",
    "    axes[1, 1].set_title('Bottom 10 Electric Vehicle Models')\n",
    "    axes[1, 1].set_xlabel('Number of Electric Vehicles')\n",
    "    axes[1, 1].set_ylabel('Model')\n",
    "\n",
    "    # Adjust layout to prevent overlap\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call functions with df\n",
    "plot_top_5_cities(df)\n",
    "plot_ev_type_by_state(df, state='WA')\n",
    "plot_top_bottom_makes_models(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Bivariate Analysis\n",
    "- **Correlation Analysis**: (e.g., Pearson, Spearman)\n",
    "- **Cross-tabulation**\n",
    "- **Visualize Relationships:** scatter plots, box plots, heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only numeric columns for correlation analysis\n",
    "numeric_cols = df.select_dtypes(include=[np.number])\n",
    "\n",
    "# Pearson Correlation Matrix\n",
    "pearson_corr = numeric_cols.corr(method='pearson')\n",
    "\n",
    "# Spearman Correlation Matrix\n",
    "spearman_corr = numeric_cols.corr(method='spearman')\n",
    "\n",
    "# Visualize Pearson Correlation Matrix using a heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(pearson_corr, annot=True, cmap='coolwarm')\n",
    "plt.title('Pearson Correlation Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Visualize Spearman Correlation Matrix using a heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(spearman_corr, annot=True, cmap='coolwarm')\n",
    "plt.title('Spearman Correlation Matrix')\n",
    "plt.show()\n",
    "\n",
    "correlation_matrix = df[['Electric Range', 'Base MSRP', 'Model Year']].corr(method='pearson')\n",
    "\n",
    "# Heatmap for correlations\n",
    "sns.heatmap(correlation_matrix, annot=True)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Cross-tabulation between Electric Vehicle Type and Clean Alternative Fuel Vehicle (CAFV) Eligibility\n",
    "crosstab_result = pd.crosstab(df['Electric Vehicle Type'], df['Clean Alternative Fuel Vehicle (CAFV) Eligibility'])\n",
    "\n",
    "# Visualize cross-tabulation using a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(crosstab_result, annot=True, cmap='Blues')\n",
    "plt.title('Cross-tabulation between Electric Vehicle Type and CAFV Eligibility')\n",
    "plt.show()\n",
    "\n",
    "# Scatter plot between Electric Range and Base MSRP\n",
    "sns.scatterplot(x='Electric Range', y='Base MSRP', data=df)\n",
    "plt.title('Electric Range vs. Base MSRP')\n",
    "plt.show()\n",
    "\n",
    "# Scatter plot ER and Model Year\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=df, x='Model Year', y='Electric Range', hue='Make', style='Make')\n",
    "plt.title('Scatter Plot of Electric Range vs Model Year')\n",
    "plt.xlabel('Model Year')\n",
    "plt.ylabel('Electric Range')\n",
    "plt.legend(title='Make', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Boxplot of Electric Range across Makes\n",
    "sns.boxplot(x='Make', y='Electric Range', data=df)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Electric Range by Car Maker')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Multivariate Analysis\n",
    "- **Pairplot/Scatterplot Matrix**\n",
    "- **Multivariate Statistics**\n",
    "- **Advanced Visualizations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, hue='Make')\n",
    "plt.title('Pair Plot of Electric Vehicle Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_data = df.groupby(['Model Year', 'Make']).size().unstack()\n",
    "stacked_data.plot(kind='bar', stacked=True, figsize=(12, 6))\n",
    "plt.title('Number of EVs by Make and Model Year')\n",
    "plt.xlabel('Model Year')\n",
    "plt.ylabel('Number of EVs')\n",
    "plt.legend(title='Make', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Feature Engineering\n",
    "- **Create New Features**\n",
    "- **Feature Transformation**\n",
    "- **Encoding Categorical Variables**\n",
    "\n",
    "Suggestion for New Feature:\n",
    "- Average ER on the City, County, Make/Model level\n",
    "- Age of Vehicle\n",
    "- Create a new feature that combines Model Year and Make to see if certain manufacturers are more popular in specific years.\n",
    "- Create a feature that combines City and Make to see which manufacturers are dominant in specific cities.\n",
    "- Range Category:\n",
    "    - Create categorical bins for Electric Range to identify different range segments (e.g., Low, Medium, High).\n",
    "    - Normalized Electric Range: Scale the electric range to a 0-1 range using Min-Max normalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9: Handle Imbalanced Data (If Applicable)\n",
    "- **Resampling Techniques**: Use oversampling, under-sampling, or SMOTE if the target variable is imbalanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 10: Analyze and Validate Assumptions\n",
    "- **Check for Multicollinearity**: Use VIF (Variance Inflation Factor) to detect multicollinearity among predictors.\n",
    "- **Normality Testing**: Test if numerical data follows a normal distribution (e.g., using the Shapiro-Wilk test).\n",
    "- **Homoscedasticity**: Check the equality of variance across groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 11: Preliminary Insights and Hypotheses\n",
    "- **Identify Key Findings**\n",
    "- **Generate Hypotheses**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1. **Most Common Car Manufacturers for EVs in Washington**:\n",
    "#   - Use `value_counts()` on the **Make** column to find the most frequent car manufacturers.\n",
    "df['Make'].value_counts().head(10)\n",
    "\n",
    "### 2. **Highest and Lowest Electric Ranges and Their Car Makers/Models**:\n",
    "#   - Find the maximum and minimum values of the **Electric Range** and identify the corresponding car models.\n",
    "highest_range = df['Electric Range'].max()\n",
    "lowest_range = df['Electric Range'].min()\n",
    "\n",
    "max_range_car = df[df['Electric Range'] == highest_range][['Make', 'Model']]\n",
    "min_range_car = df[df['Electric Range'] == lowest_range][['Make', 'Model']]\n",
    "print(max_range_car, min_range_car)\n",
    "\n",
    "### 3. **Is the Maximum Electric Range Unique?**:\n",
    "#   - Filter the dataset to check how many vehicles have the maximum electric range.\n",
    "cars_with_max_range = df[df['Electric Range'] == highest_range]\n",
    "cars_with_max_range\n",
    "\n",
    "### 4. **Is the Minimum Electric Range Unique?**:\n",
    "#   - Similar to the maximum range, filter to check how many cars have the minimum electric range.\n",
    "cars_with_min_range = df[df['Electric Range'] == lowest_range]\n",
    "cars_with_min_range\n",
    "\n",
    "### 5. **Variation in Electric Range Between Car Makers and Models**:\n",
    "#   - Use `groupby()` to calculate the average electric range by car maker and model.\n",
    "range_by_maker_model = df.groupby(['Make', 'Model'])['Electric Range'].mean().reset_index()\n",
    "range_by_maker_model\n",
    "\n",
    "### 6. **Top 5 Cities Adopting EVs**:\n",
    "#   - Use `value_counts()` on the **City** column to find the top 5 cities with the most EVs.\n",
    "top_cities = df['City'].value_counts().head(5)\n",
    "top_cities\n",
    "\n",
    "### 7. **EV Adoption Rate by Car Makers Over the Years**:\n",
    "#   - Use `groupby()` on **Make** and **Model Year** to track how EV adoption has changed over time.\n",
    "adoption_rate_by_maker_year = df.groupby(['Make', 'Model Year']).size().reset_index(name='Count')\n",
    "adoption_rate_by_maker_year\n",
    "\n",
    "### 8. **Correlation Between Electric Range and City**:\n",
    "#   - This can be checked using correlation analysis between **Electric Range** and **City**.\n",
    "#   - Since cities are categorical, you may need to encode the cities and then calculate correlation.\n",
    "\n",
    "# [Result]\n",
    "\n",
    "### 9. **County with the Greatest Variety of EV Models**:\n",
    "variety_by_county = df.groupby('County')['Model'].nunique().reset_index(name='Unique Models')\n",
    "top_county = variety_by_county.sort_values(by='Unique Models', ascending=False).head(1)\n",
    "top_county"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 12: Document and Communicate Findings\n",
    "- **Create Visual Summaries**\n",
    "- **Write a Summary Report**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 13: Next Steps\n",
    "- **Plan for Further Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 14: Review and Reiterate\n",
    "- **Review EDA**\n",
    "- **Iterate as Needed**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
